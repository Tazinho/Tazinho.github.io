---
title: "rstudioconf"
---

## talk1 summary: tidyverse talk von hadley auf rstudio conf

quelle: rstudio talk hadley:  https://www.rstudio.com/resources/videos/data-science-in-the-tidyverse/

goal:solve complex problems by combining simple uniform pieces
-consistent functions
  - a command function performs an action (print, plot, write_csv, <-
  - a query function computes a value (summarise, mutate, geom_line)
pipe code
 - first argument is the data
 - the data is the same type across a family of functions
Tidy data is a consistent way of storing data
 - Each dataset goes in a data frame
 - Each variable goes in a column
for list columns use tidy tibbles instead of tidy data frames
biggest difference: tibbles are data frames that are lazy and surely
no character to factor, no partial matching, better support for lists (defining in the creator for example)
- applications: tidy text, sf (successor of the sp) uses list columns, cross validation (with list columns), tidy_quant (tidy financial timeseries), maybe ml with caret (or mlr) pipelearner, ...

4 principles:
1. each function encapsulates one task
2 and is either a query or a command
3. Functions are composed with "%>%"
4. and use tidy tibbles as primary data structure

workflow usually involves naming intermediate results, nesting and the pipe
when working with many data frames it mitght be not alway the best idea

dbi interface for the odbc will be worked on

## talk2 building dashboards with shiny tutorial j cheng

first part joe cheng, server side

what sets a dashboard apart from ohter apps

- automatic updating
- potentially many viewers looking at the same data
- may or may not be interactive
- "Ten foot" user interface (designed to be seen from a distance or from mobile, ...)

techniques:
- 1. reactive file reader/pull functions
- 2. optimizing performance

1. user vs data driven events
invalidate later() is ok but has overhead
- reactivefilereader just looks every i. e. milisecond on the timestamp of a file and the read functions are only called when the timestamp changes.
first argument must be the path to data. but works just for data in files on disk. not for databases or apis
- reactivePoll is 2 functions first is checkfun (httr::head(api) head request for apis to see if anything changed), 2nd is valueFunc both are necessary for api or db data. no data is returned, but a reactive expression that returns a data frame.

how do we filter arrange etc while data changes underneath...
just to understand...it is done more or less automatically

2 performance
- Cache Results
- speed up with logic, parallel or rcpp
- scale hardware up/out
- remove functionality
.maybe rxtools package is coming to handle special functionality for reactivity, but maybe under a different name
.maybe some background job functionality will be included in shiny
.logging was not well introduced via shiny

Userinterface (W. Chang)
1. dynamic (in clientside with html widgets) vs stable dashboards
2. flexdashboard (publish on server, RPubs, RStudoConnect, works with html_widgets, crosstalk and shiny, also auch mit reactive inputs im letzten Fall, galube ich...)
3. shinydashboard
(of course one can build a shiny dashboard without these packages)

deploy to server ,rstudioapps.io, rstudioconnect

## talk 3 happy R users purrr - Tutorial (charlotte wickham)

lapply(people, function(x) length(x$starships))
is equivalent to
map(mtcars, ~ length(.x$starships) # map(.x, .f)

- other types of output
map always returns a list
some helpers for atomic returns use: map_lgl, map_int, map_dbl, map_chr (return has the same length as x). use them to have typestable output.
u can use readr::parse_number for also telling what are NAs when converting to numeric
when you want nothing at all, use a function for its sisde effects: walk()
set names with set_names instead of names of setNames
- other ways of specifying .f
.f can be an integer or string, i.e. f  = "some_name"  instead of .x[["some_name"]]
go in little steps: map(people, "starships") %>% map_int(length)
- other iteration functions

when you have more than one information for a cell. try to use a list column. try to use it inside a tibble instead in a data.frame. when building the tibble from scratch with map, there is no nice functionality to turn the list to a tibble, but you really have to build every column from scratch indepentently...you can use transpose to try it, but at the moment there is no "safe" way to do this in short

convenient functions for missing values map_chr("Species", .null = NA_character_)

use map inside mutate to manipulate list columns inside a tibble/data.frame
...sometimes it's nice to use lookup tables inside map...

collapse a character list column, so that each element is a paseted strings with an appropriate separator (use collapse) -> sth like
mutate(new_col = paste(old_col, collapse = ", "))
so the following should work:
map_chr(old_column, paste(.x, collapse ", ")) # before pasting one can sort and so on of course.

walk is like map, but you get nothing back (you get it back invisible, so you can do some side effect inside a pipe and continue the pipeline in the same go).
side effects = "printing to screen, plotting to gr dev, file manipulation (save, write, move, etc), system calls"

map2 iterates over to listts -> map2(.x, .y, .f)
there are also
walk2, map2_lgl, map2_int, map2_dbl, map2_chr

use map2 for writing, downloading etc different objects to different files...
use pmap, it is like map and map2, just for 3 or more arguments
use invoke map to apply many different functions to one argument

many helpers for lists and functions..
safely takes a function and returns a function
transpose takes and returns a list...
the combination of the last two is very good for dealing with errorcatching...

## talk4 What’s new with Shiny – Joe Cheng

near future:
- automated testing
  - shiny tests
  - write tests
  - run tests
  - update in a sandbox and run tests
  - compare tests
  - decide if you can take the update or have to debug
  + test event recorder to record named tests for the userinterface
  -> json of the shiny states during the recording/snapshot, and also png to get the overall picture of
      the bug
- api endpoints

after that:
- asynchronous tasks

limitations:
- not suitable for all cases. for example not for random actions (maybe set.seed)
- api might change (its not on cran yet)
- some dependencies (cran again)

- possibility to catch values with api that were created by interactive use of shiny
- usage /api/... you get the data as csv, json or whatever you define
- readable from python, r, c#, whatever
- possibility for api to activate the interactive widgets
- at the moment only data retrieving and no authentification at the moment

## talk5 Database Best Practices – Jim Hester

- shows latest work at dbi, odbc, pool

- dbi is a unified interface for databases
- (was alos available for s+)
- rstudio took over maintenance
- will be in next dplyr release
- databasebackends just have to work with dbi interface,
- no need anymore to customize dplyr backends specifically
- dbitest for tests...

- odbc will be on cran
- is dbi compatible
- is a rewrite of the rodbc package
- odbc standard is separate from this "odbc" package
- every odbc connectable database backend might be used with this package
- native support for timestamps and raw binary formats (no coercing date-> string necessary ...)
- supports batch queries, which makes it a bit (~ 2times) faster than rodbc
- supports parameterized queries
- includes some wrappers for strings to avoid dropping tables in the db-backend
- insert into xyz (?,?),dbBind() (so you can set r objects as parameters, "?" are placeholders)

- u can set a knitr option (connection = con)
- u can use sql code chunks in knitr, it will know the connection if set in options
- u can write queries as functions and give arguments to interact with the result...
(maybe it would be good to catch the result, will have to look at the memory issues)
- u can build a shiny app to interact with the database

- pool makes it possible to let many people interact with a database (maybe interacting with the db)
- issues before, r is single threaded, so everybody has to wait. other solution: new connection for each person, but there is a limit for maximal open connection.
- pool opens some connections and gives connections that are already open.
- pool is faster, because ...
- tries to reestablish connection (and you dont have to care about too many details, when failure occur)

future:
- generic connection tab in rstudio (like the one for sparklyr)
- reestablish previous connections
- viewer for available drivers
- view sources
- view tables
- view schemes
-> within rstudio v 1.1 <3

rstudio server pro:
- easy setup for a wide variety of db (50+, including hive, impala, postgresq, mysql)
- improved performance
- improved error messaging
- kerberos support

## talk6 Push-Button Publish in RStudio Connect – Jeff Allen

how to safe achievements?

- email, sharepoint, ...
-> rstudio connect
one button from rstudio to rstudio connect and managing the publish stuff
- self managed content like markdown, shiny, plots
- scheduled rendering
- enterprise security
- on premise, commercial support
- creates the same environment on the server like the one which was used locally (all packages,...)
- publishing options private, public, ...
- returns a url, which will be refreshed when reports are updated
- schedule rmarkdown reports
- good idea to use parameterized rmarkdown, can be defined in the yaml block of rmd files -> knit with parameters... these will also work, when published. Then the reports can be filtered by users and regenerated per push button by the user. You get the full functionality without thinking about shiny.
- you can get emailed copies of the reports

- also able to host shiny, with multiple processes and loadbalancers
- you can get the logs (on r studio pro)

- to rebuild the environment, packrat is used.
- it-friendly (enterprise), auth, passwords, monitoring,...
- beta for a year now

next:
- self content organization
- choosing the hierarchy
- usage of tags
- kerberos support
- bundle management
- rollback

- feature to load up source code

- free day 45 trial
- also hosted by rstudio
- available on linux/virtual machine

## talk 7: R and Spark – Javier Luraschi
- test locally, spark_install(), spark_connect(master = "local")
- copy data to spark, use dplyr, ...
- for modelling use sparkfunctions
- dont need dplyr, you can also use dbi package and use sql statements
- supports extentions: run scala from sparklyr, via invoke(context, version), runs on the cluster
- use scalafiles, get results to r interface (advanced)
- more functions
- more r behaviour, df, and NAs
- experimental livy support (to connect remote from rstudio)
- rstudio and shiny server pro certified with cloudera
- config[[spark-shell-memory]] or so to give more memory then 500mb default or so


## talk 8: Dynamic Shiny Interfaces – Bárbara Borges Ribeiro
- dynamic ui means that you return a plot, a summary or a table depending on the choose of a user
- there are not too many use cases, since normally one works only on a table or only on a table...
- should one use render or input ui
- render ui generates a slot for the output and however we choose the input, we just get the specific output
- basically you use just regular shiny objects
- there are limitations for render ui. if you have 30 inputs and maybe want to see some of them at the same time. its possible, but then you had to provide outputslots for them, which you would like to do independently.
- example: add independently different functions on different datasets
- instertUI: works like renderUI. Needs an action button. you have to define where new output is added (usually starting with some placeholder). it doesnt look like usual shiny. no ui-server pairs.Wrap things into tag list and div.
- summary:
 - renderUI, feels more like "shiny" and is a bit safer, brings less trouble, doesn't need events (has reactivity by default), easily bookmarkable
 - insertUI is a lot trickier, you have to know a bit what you are doing. Is a lot more flexible. You can do everything like with renderUI, but also much more, longer code, harder to debug and to bookmark,
 it is nice to compare different plots or other things side by side.
- there are also other ways for dynamic shiny, like conditional panels or any javascript stuff.
- you should use renderUI, when reactive ui is enough.

## talk9 Using Web APIs from R – Amanda Gadrow

- some nice api packages:
 aws.s3, RGoogleAnalytics, acs, etc.
- httr for requests (lots of functionality and very consistent)
- xml2, jsonlite for parsing the response

# goal
# verb (get for example)
# endpoint (url)
# parameters (keyword, tag,... -> query)

usage:
GET(), content(), fromJSON, stop_for_status() (in pipes to invest the header), writing helpers to parse sometimes, GET(page$next) to go through pages, possible to write this as a loop via
while (!is.null(page$next))

you can schedule api calls via rstudioconnect (or other ways),
you can also run them regular from s3

## talk11: Competitive Modeling of Outcomes for Prediction – Max Kuhn
- gain & lift...

## talk12: Fun with htmlwidgets:3D interactive network visualization with threejs and R – Bryan Lewis
- introduced 2 years ago
- now first major update
- less to learn, less overhead ...
- good combi with other packages especially igraph
- can do graphs on globes
- scatterplot3js is the internal working horse
- new: network visualisation with graphjs function, similar to igraph (extends it)
- easy animation
- 3d layouts
- easy to play with really big graphs

## talk 13 Writing Readable Code with Pipes – Bob Rudis

- 81 Packages on Cran that export the pipe operator
- use ndjson for faster json parsing
- use anytime for faster date time stuff
- use stop_for_status() to look into the risky data stuff within the pipeline
- use list.files %>% map_df

## talk 14 (d1) Mapping in R with Leaflet – Bhaskar Karambelkar

- based on version 0.7 of the leaflet javascript library.
The most actual one is version 1.0
- pacakges of the presentation: sp, rgdal, rgeos, raster, rmapshaper, tigris, acs, sf,  mapview, geojson, geojsonio
- the wholel grafic is rendered as a svg
- many controls, buttons and plugins (the latter is outstanding and special within leaflet).

Adv. Concepts
- various panes with different visibility. Order of mapping is not important, cause this is done internally.
- u can catch events for html stuff or shiny
- u can use groups and players
- huge mass of plugins, a whole ecosystem (like also d3 has).

-leafletProxy is used within shiny to add sth to already existing maps
- leaflet/adxxx have options arguments, which can be quite nice
- you can use tiles from cartodb
- addLayersControl("Dark", "Light")
- new markers: addAwesomeMarkers, addLabelOnlyMarkers

- more hover options, also for polygons...
- better and more projections like mercator...
- use shiny to capture events,..

- leaflet.extras, for added plugins...
- at the moment on github. on cran soon...
- leaflet will be stable
- leaflet.extras will be dynamic

- topojason for dynamic chloropleth maps is awesome...
- for now everything thrown into leaflet has to be in lat/lng. however this is discussed and might be more flexible someday

## talk16 Linking HTML Widgets with Crosstalk – Joe Cheng
- crosstalk is somehow the webbased extension of cranvas and/or ggobi (coordinated multiple views)
- htmlwidgets is unopinionated, you have all freedom to access any js library, ...
- three approaches to this: crosstalk, shiny, js (robservable)
- filtering and linked brushing for data based on data frames (crosstalk)
syntaxdifferences:
data <- quakes;                           leaflet(data) %>% addMarkers; datatable(data)
vs
data <- SharedData$new(data); leaflet(data) %>% addMarkers; datatable(data)

## talk 17: Text Mining the tidy Way – Julia Silge
- get a text, safe the line, use unnest_tokens(word, text) and get the format of one word per row.
- stop words: tidy_books %>% dplyr::anti_join(stop_words)
- counts: tidy_books %>% dplyr::cout(word, sort = TRUE)
- sentiments analysis: tidy_books %>% inner_join(get_sentiments("bing"))
- what is a document about: inverse document frequency (better than removing stop words): calculate for each book how often each words occurs (in percent).
 tf_idf: ...
- if you have tagged articles it is nice to sort the included words by the heights of their tf_idf's
- ngrams, networs, negates (skipped)
- convert between tidy and non tidy formats. allows you to use operations on classical textmining datastructures with the classical implemented methods. than you can switch back to the tidy format.
- book: tidy text mining (includes case studies)
- if you have different speakers, extend then to a column, before unnesting into the tidy format

## talk18 TrelliscopeJS – Ryan Hafen
- interactive displays of small multiples
- based on the javascript package from the same author
- facet_trelliscope fits in the ggplot workflow, but gives you pages of facets, which can lead to a better overview.
- it also gives you filters and sorts
- facets can include plotly graphics (so widgets inside a widget)
- plots list columns of plots (interactive)
- fits well with tidyverse workflow
- works good with sparklyr
- "kind of a database of images that you can query"
- a lot more to come, especially filters for more datatypes
- should work with base, lattice, ggplot2 and any html widget, bokeh, plotly, etc
- uses crossfilter behind the scenes (should work for 1 million rows (or more?))
- works in browser, so there are limitations...
- fit in one markdown vis
- has bookmarkable/sharable state

## talk 19: Teaching Introductory Statistics Using the tidyverse via bookdown – Chester Ismay

- bringing R to different subjects in school
- writing a book to lower the barrier to return to the language
- writing a book to use the interactive and build up a formula paradigm

## talk 20: Lightning Talks – User Submitted Talks

1. easyMake (package)
- tries to build dependency graphs of analysis
- tries to build make files upon
- also has an RStudio plugin
- gives a working makefile, not a perfect one

2. ROpenSci packages every muggle should have heard about (Kathik Ram)
- Magick package, helps you with images transformate, read, write, some magic stuff, ...
  - perfect with gganimate
  - pipefriendly
- hunspell
  - spellcheking in R for text and textanalysis
  - lots of advanced functionality
- Tesseract
- Travis + tic
  - add tic to your travis yaml

3. Scalable Data Science with R and Spark – Best Practices and Lessons Learned
 - Rdd
  - DataFrames
   - Transformers
    - Actions

4. ggedit: interactive ggplot aesthetic and theme editor

5. Exploring correlations in a tidy R framework with corrr
- correlations in data frames instead of a matrix
- use stretch() for long format
- everything pipeable
- fcts for printing, plotting, clustering
- recomments widyr for structures that are not perfect for tidy format

6. Exploration of Literature Databases with Shiny
- shiny in production

7. Business intelligence with R
bi plattform ending in R
backend + data (googlesheets, mysql, python, crm, ...) -> googlebigquery -> flexdashboard (incl. shiny, used a child rmd file -> every page has its own file) + highcharter

8. bsplus: Using Bootstrap to extend your Shiny app
- you want to put more stuff into your shiny app
- a lot of additional stuff depends on the ui, not the serverside
- everything pipeable
- is coming to cran

9. Bringing R Into Dev: Playing Nice With Others
use shiny, bash and feather. the latter plays nicely with python and julia

10. FlashR: Parallelize and Scale R Machine
- redefines r matrix functions to work with bigger data (overwrites them)
- mainly switches functions that create r objects into functions that create flashR objects
- uses same api as base r
- brings parallelization out of the box
- executes (and stores) out of memory
- outperforms revolution r :D
- easy to use, fast and you can test it on the webpage flashx.io

## tallk21: Finding and Telling Stories with R – Andrew Flowers
subtitle "6 types of data stories and how to find them"
- good journalism is good storytelling

## talk 22 Advanced R Markdown Tutorial – Yihui Xie
- rmarkdown = knitr + pandoc
- raw (outside of a chunk) latex or html will only work in the specific documenttype
- converts to markdown and markdown passes arguments to pandoc
- outputformate können über output_format's basetype argument angepasst werden
- yaml is translated into rmarkdown::render arguments
- you can set some yml options to null, like theme bootstrap (default) can changed and that makes output sometimes smaller
- can pass own css styles
- use developer tools (for example in chrome) . you can customize the html tag p for paragraph within the browser (as experimentation add for example color: red;) and later change this directly in rstudio via copy paste and saving the css as external css file and apply this to yml via css:path/of/css/file. you can do the same with javascript.
you can do this as a vector; css: [path1, path2, path3]
- you can also customize via the template option. defaults for templates are on github.
- only output field of yml is for markdown. the rest is for pandoc and can be found in its documentation
- some nice deeper customization is available via in.header, before.body, after.body
- you can write your own package to extend further options
- how markdown handles this internally is explained in the talk
- via pre and postproces, you can change some things, that can't be done with pandoc.
- this is for example used to preserve html widgets content in rmarkdown
- most important for using/providing a template is the yml output
(2 approaches are shown [jss rticlle, tufte handout])
- xaringan ports remark.js but some markdown shoudnt be touched by pandoc. therefore you can hide somehow some part of it via the preprocessor step explained before. (the document /html parts can be broken via some line with a split...)
- it is an awesome presentation framework, (haked by yihui within 3 days)
- bookdown (worked on it whole 2016). outputs: pdf, html, ebooks. writing on a specific postprocessor took most of the time, cause many features had to be synchronized between different  output formats (the real challenge is to make sth work for multiple outputformats at the same time.). makes extensive use of regular expressions.
- three tips from his life as a software developer:
1. you cant make everyone happy. focus first on making one person veryvery happy.
2. use humor and provide little easter eggs. think differently
3. stand on the shoulders of giants. you dont have to know about c, c++, python, ..., but you can reuse frameworks and build up on them or their ideas.
4. keep calm, say no, say sorry, if it is too complex problem. and has a very easy practical workaround that is easy for the user. it will be ok for them.
5. reask the user why he wants sth. maybe his intention is strange and afterwards he doesnt  have the feature request anymore.
6. be very open and engagng to users in the open source and pull requests. maybe others can contribute and work further on your package

## talk 24 (d2) Opinionated Analysis Development Hilary Parker
~ try to blame the process and not the person -> when errors occur, optimise the process

## talk 25: What’s New with the IDE – Kevin Ushey
- uses up to date version 1.0.136 in the talk
  - lots of autocompletion via tab, in different linces, in and outside of functions, fuzzily, for paths, ...
  - works also nice when implementing shiny stuff
  - is smart to know, when u want...for example an environment, options, ...
  - autocompletes the methods for object.method syntax within rcpp
- there is a new "Rstudio Home button" in the rstudio-file-pane
- diagnostics
  - u get symbols noting when code is expected to fail, because of some syntax related errors,
  - but there are some other cool thins, like unknown function arguments, no definition in scope, defined, but not used
  - configurable inside options -> diagnostics
  - some small things, like defining whitespaces around binary operators.
- command + enter executes a whole expression
- cmd + alt + shift + up/down to expand selections, for example if statements
- rename in (parent/bracket) scope (can be done via the gui, but there is also a shortcut)
- some nice stuff for roxygen
- some nice stuff for s4 classes
- highlight ugly code and press cmd + shift + a to format to nice code
- strg + alt gives you multiple cursors
- there is a document outline view in the gui for rmarkdown now
- strg + alt + i to use code chunks
- inline latex $$
- can execute and render python (and many other) chunks (uses default engine, but you can set this path)
- alt + shift + k for shortcuts

## talk 31: Extending R with C++: A Brief Introduction to Rcpp – Dirk Eddelbuettel
- computer age statistical inference by hastie and efron (book recommendation)
- in this state of the art book, everything is done with r :)
- extendig r by j. m. chambers, opening in chapter 1:
  - everything in r is an object
  - everything that happens in r is a function call
  - interfaces to other software are a part of r
- r is a c program (and r and fortran, ...) and you can expand this, so there is already an api, via the .call interface, .c is deprecated.
- you always get an SEXP back (mapping from r objects to c), we can have this for all r objects.
- dont need to do memory allocation, just allocate a vector...
- library("Rcpp")
- evalcpp("2+2") # testcase
- cppfunction("some code", plugins = c("cpp11"))
- sourceCpp is workhorse behind evlCpp function
- rcpp function initialisation does compile, link, load
- use it in/with packages. do "package with rcpp" when creating a package
- u can extend your packages with templates for rcpp, eigen, armadillo, devtools
- 3 ways to extend r with rcpp
  - just use the rcpp objects
  - use LinkingTo for other only header pacakges like, eigen, armadillo, BH
  - doable: external libraries may require a little bit more work but entirely feasible
- many rcpp versions of ml algorithms available
- gallery rcpp with 100 examples, + book, + website

## talk 33 (d2) R’s Role in Data Science – Joseph Rickert

distinction of data engineering vs data science
"most of the time engineers know what they are doing"

ds:bring scientific method into engineering
...

## Talk 34 (d2): All Things R and RStudio, Q & A with J.J. Allaire, Hadley Wickham & Joe Cheng, Moderator: Joseph Rickert

upcoming:
interface to tensorflow deep learning and machine learning
thoughts about default parallelization...problems about api, because parallelisation ways differ so much on different os'ses.

Needed in base R:
64bit integers
out of memory vectors (pointers)